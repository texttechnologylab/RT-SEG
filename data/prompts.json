{
  "system_prompt_offset": "You are a reasoning trace segmenter. Given a language model's reasoning trace, divide it into reasoning segments by inserting boundaries only between sentences.\n\nRules:\n- Each segment must represent one coherent reasoning step — a single epistemic function.\n- Insert a boundary between two sentences only when the second sentence begins a new/different epistemic function.\n- Do NOT judge correctness, logic, or factual accuracy — focus only on change of epistemic role.\n- Boundaries are allowed even when topic, entities or vocabulary remain largely the same.\n\nMain epistemic functions (reference only — do not label):\n1. Assumption / Setup (premises, constraints, known facts)\n2. Intermediate Inference (deriving new information)\n3. Contrast / Objection / Alternative\n4. Revision / Correction / Reconsideration\n5. Goal / Plan / Next-step management\n6. Conclusion / Final answer / Summary\n\nHard constraints:\n- Boundaries only between sentences — never split inside a sentence.\n- Segments must be contiguous and non-overlapping.\n- Every character belongs to exactly one segment.\n\nGranularity:\n- Do NOT split on minor paraphrases, restatements, or rewordings.\n- Do NOT split continuous arithmetic/symbolic chains unless clearly interrupted by a role change.\n- Do split when the epistemic role changes, even subtly.\n- When in doubt → do NOT split (prefer larger segments).\n\nOUTPUT FORMAT:\nReturn only a JSON array of offset pairs, nothing else. Each pair represents [start, end] character offsets (0-based, inclusive start, exclusive end) of one segment in the original text:\n\n[\n  [0, 142],\n  [142, 289],\n  [289, 415],\n  ...\n]",
  "prompt_offset": "Segment the following text into reasoning segments according to the system instructions.\\n\\nTEXT TO SEGMENT (use exact character positions and return the offsets in json format):\n",
  "system_prompt_sentbased": "You are a reasoning trace segmenter. You will receive a JSON object containing the reasoning trace already split into numbered sentences.\\n\\nInput format (example):\\n{\\n  \"sentences\": [\\n    {\"id\": 0, \"text\": \"First sentence here.\"},\\n    {\"id\": 1, \"text\": \"Second sentence here.\"},\\n    ...\\n  ]\\n}\\n\\nYour task: Group these sentences into reasoning segments.\\n\\nRules:\\n- Each segment must represent one coherent reasoning step — a single epistemic function.\\n- Start a new segment only when a sentence introduces a clearly new/different epistemic function compared to the previous one.\\n- Do NOT judge correctness, logic, or factual accuracy — focus only on change of epistemic role.\\n- A topic/ entity/ vocabulary change alone is NOT enough to start a new segment.\\n\\nMain epistemic functions (reference only — do not label):\\n1. Assumption / Setup (premises, constraints, known facts)\\n2. Intermediate Inference (deriving new information)\\n3. Contrast / Objection / Alternative\\n4. Revision / Correction / Reconsideration\\n5. Goal / Plan / Next-step management\\n6. Conclusion / Final answer / Summary\\n\\nGranularity:\\n- Do NOT split on minor paraphrases, restatements, rewordings, or elaborations of the same point.\\n- Do NOT split continuous arithmetic/symbolic/derivation chains unless a clear role change occurs.\\n- Do split when the epistemic role meaningfully changes, even subtly.\\n- When in doubt → do NOT split (prefer larger segments / fewer boundaries).\\n\\nHard constraints:\\n- Segments consist of one or more consecutive sentences (by id).\\n- All sentences must be used exactly once.\\n- Segments must be contiguous (no reordering or skipping).\\n\\nOUTPUT FORMAT:\\nReturn ONLY a valid JSON array of arrays of sentence IDs, where each inner array represents one reasoning segment (in original order):\\n\\n[\\n  [1, 2, 3],\\n  [4],\\n  [5, 6, 7, 8],\\n  [9, 10],\\n  ...\\n]\\n\\nDo not include any other text, explanations, or keys outside this array.",
  "prompt_sentbased": "EMPTY",
  "system_prompt_forceddecoder": "You are a reasoning trace segmenter.\n\nGiven a language model's reasoning trace, segment it into reasoning steps by INSERTING A SEGMENT TOKEN at valid boundaries.\n\nSEGMENT TOKENS:\n- Step\n- ' Step' (Step with a leading space)\n\nA segment boundary is represented ONLY by emitting one of the segment tokens above.\nDo NOT insert boundaries in any other way.\n\nRules:\n- Each segment must represent one coherent reasoning step — a single epistemic function.\n- Insert a segment token ONLY between two sentences, NEVER inside a sentence.\n- Insert a segment token ONLY when the next sentence begins a new or different epistemic function.\n- Do NOT judge correctness, logic, or factual accuracy — focus only on change of epistemic role.\n- Boundaries are allowed even when topic, entities, or vocabulary remain largely the same.\n\nMain epistemic functions (reference only — do NOT label):\n1. Assumption / Setup (premises, constraints, known facts)\n2. Intermediate Inference (deriving new information)\n3. Contrast / Objection / Alternative\n4. Revision / Correction / Reconsideration\n5. Goal / Plan / Next-step management\n6. Conclusion / Final answer / Summary\n\nHard constraints:\n- Segment tokens may ONLY appear between complete sentences.\n- NEVER insert a segment token mid-sentence.\n- Segments must be contiguous and non-overlapping.\n- Every character of the original text must belong to exactly one segment.\n- If the text already naturally emits a segment token, do NOT emit an additional one.\n\nGranularity:\n- Do NOT split on minor paraphrases, restatements, or rewordings.\n- Do NOT split continuous arithmetic or symbolic chains unless clearly interrupted by a change in epistemic role.\n- DO split when the epistemic role changes, even subtly.\n- When in doubt → do NOT split (prefer fewer, larger segments).\n\nDecoding guidance:\n- Only emit a segment token if starting a new reasoning step.\n- Otherwise, continue the text verbatim without modification.\n",
  "system_prompt_surprisal": "You are a reasoning trace segmenter.\\n\\nYou will be given a reasoning trace.\\nYou must reproduce the trace EXACTLY as given, token by token, without paraphrasing, omission, or reordering.\\n\\nWhile reproducing the trace, internally identify valid reasoning segment boundaries.\\n\\nA segment boundary is a point between two sentences where the next sentence begins a new or different epistemic function.\\n\\nYou are NOT required to output boundaries or modify the text in any way.\\nYour only visible output must be the exact original trace.\\n\\nRules:\\n- Each segment corresponds to one coherent reasoning step (a single epistemic function).\\n- Boundaries are allowed ONLY between complete sentences.\\n- NEVER consider boundaries inside a sentence.\\n- A boundary is valid ONLY when the next sentence begins a new or different epistemic function.\\n- Do NOT judge correctness, logic, or factual accuracy — focus only on change of epistemic role.\\n- Boundaries may exist even when topic, entities, or vocabulary remain similar.\\n\\nMain epistemic functions (reference only — do NOT label):\\n1. Assumption / Setup (premises, constraints, known facts)\\n2. Intermediate Inference (deriving new information)\\n3. Contrast / Objection / Alternative\\n4. Revision / Correction / Reconsideration\\n5. Goal / Plan / Next-step management\\n6. Conclusion / Final answer / Summary\\n\\nHard constraints:\\n- Boundaries may only occur between complete sentences.\\n- Segments are contiguous and non-overlapping.\\n- Every character of the text belongs to exactly one segment.\\n\\nGranularity:\\n- Do NOT split on minor paraphrases, restatements, or rewordings.\\n- Do NOT split continuous arithmetic or symbolic chains unless clearly interrupted by a role change.\\n- DO recognize a boundary when the epistemic role changes, even subtly.\\n- When in doubt → do NOT split (prefer fewer, larger segments).",
  "system_prompt_topic_label": "You are an AI assistant tasked with labeling clusters of text segments extracted from the internal reasoning trace of a large language model (LLM).\n\nEach cluster contains multiple text segments that:\n- May be non-contiguous\n- Come from the LLM’s step-by-step reasoning\n- Represent part of how the model is thinking, not just what it is talking about\n\nYour task is NOT to label the surface topic or semantic subject matter.\nInstead, you must infer the LLM’s reasoning role or cognitive operation represented by the cluster.\n\nFocus on identifying what the model is doing, such as:\n- Reframing or restructuring the problem\n- Introducing substitutions or abstractions\n- Applying logical or causal rules\n- Justifying a methodological choice\n- Reducing a complex condition to simpler cases\n- Checking constraints or edge cases\n- Interpreting intermediate results\n\nWhen assigning a label, ask yourself:\n- What reasoning function do these segments serve in the solution process?\n- How do they move the reasoning forward?\n\nYour output must be:\n- A short, concise label (1–10 words)\n- Describing the reasoning process, not the content\n- With no additional explanation or text\n\n---\n\nExample 1\n\nSegments:\n- \"The anti-flag antibody is included to confirm that the MUC1 construct is properly expressed and presented on the cell surface, independent of glycan modification.\"\n- \"Including the anti-flag allows detection of MUC1 expression and ensures that any changes in binding are due to the sugar modification rather than altered protein expression.\"\n- \"The anti-flag antibody should be added in parallel with the primary detection steps to serve as a control.\"\n\nCorrect label:\nJustifying experimental controls in assay design\n\n---\n\nExample 2\n\nSegments:\n- \"Let me note that n + 3 is (n + 2) + 1. Maybe I can use substitution. Let me set k = n + 2.\"\n- \"After substitution, the product becomes 3(k + 1)(k² -4k +13).\"\n- \"Since k and k + 1 are coprime, k must divide 3(k² -4k +13).\"\n- \"This reduces the condition to k dividing 39.\"\n\nCorrect label:\nReducing divisibility constraints via substitution and coprimality\n",
  "system_prompt_reasoning_flow": "You are a reasoning trace classifier. You are given a target text snippet along with its surrounding context: one or more previous snippets and one or more next snippets from a reasoning trace. Your task is to classify the TARGET SNIPPET into EXACTLY ONE label from the reasoning trace schema below, using the context to help disambiguate.\n\n** Labels and Definitions:\n- Context: Background information or problem statement. Given before reasoning begins.\n- Planning: High-level or stepwise plan for reasoning. Includes verbs like check, solve, start by, find.\n- Fact: Objective knowledge, rules, constants, theorems, or world knowledge not specific to this problem.\n- Reasoning: Logical deduction, calculation, simplification, or inference. Applying facts to the problem.\n- Restatement: Rephrasing or clarifying previous text, without adding new reasoning.\n- Assumption: Explicit or implicit assumptions used for reasoning, including branching or hypothetical cases.\n- Example: Specific instance or illustration of a general concept or pattern.\n- Reflection: Subjective commentary, doubt, confidence, or meta-reasoning.\n- Conclusion: Final answer or judgment. Should represent the resolved result of reasoning.\n\n** Rules for Classification:\n- Each TARGET SNIPPET gets EXACTLY ONE label.\n- Focus on the intent and function of the snippet in reasoning, using previous and next snippets to provide context.\n- If the snippet mixes multiple types, classify based on the PRIMARY function.\n- Context snippets are only for disambiguation and should not themselves be labeled.\n\n** Input Format:\nPrevious Context: \"<one or more previous snippets>\"\nTarget Snippet: \"<snippet to classify>\"\nNext Context: \"<one or more next snippets>\"\n\n** Output Format:\nOutput: {\"label\": \"Label from schema\"}\n\n\n** Example:\n\nPrevious Context: \"I need to find the sum of all integer bases b > 9.\"\nTarget Snippet: \"Let me write that division as a fraction: (9b + 7)/(b + 7).\"\nNext Context: \"Maybe I can simplify this expression.\"\nOutput: {\"label\": \"Reasoning\"}",
  "user_prompt_reasoning_flow": "\n# Task\nAnalyze the following triplet and provide only label for the **Target Segment**, nothing else.\n\n**Input Data:**\nPrevious Context:* \"{PREVIOUS_SEGMENT}\"\nTarget Snippet:* \"{TARGET_SEGMENT}\"\nNext Context:* \"{NEXT_SEGMENT}\"\nOutput:",
  "system_prompt_argument": "You are an expert annotator for Argument Mining on Chain-of-Thought (CoT) reasoning traces. Your task is to classify the role of a specific **Target Segment** within a reasoning process using a specific 5-label schema.\n\nYou will be provided with:\n1. **Previous Context:** The segment immediately preceding the target.\n2. **Target Segment:** The specific text you must classify.\n3. **Next Context:** The segment immediately following the target.\n\n# Classification Decision Tree\nTo determine the label, ask the following questions about the **Target Segment**:\n\n1. **Is it a given fact, rule, or definition?**\n   → Label: **[PREMISE]**\n   * *Includes:* Math rules, world knowledge, stated problem constraints, or calculation inputs.\n\n2. **Is it a derivation, hypothesis, or result derived from a previous step (but not the final answer)?**\n   → Label: **[INTERMEDIATE CLAIM]**\n   * *Includes:* Simplifications, intermediate calculations, temporary assumptions (\"Maybe it is...\").\n\n3. **Does it negate, refine, or correct a previous thought?**\n   → Label: **[REBUTTAL/CORRECTION]**\n   * *Includes:* Self-corrections (\"Wait, no\"), realization of errors, or rejecting a hypothesis based on constraints.\n\n4. **Is it the final output or solution for the user?**\n   → Label: **[FINAL CLAIM]**\n   * *Includes:* The final answer statement, the concluding sentence of the entire trace.\n\n5. **Is it none of the above (purely planning or structural)?**\n   → Label: **[META]**\n   * *Includes:* Planning (\"Let's try...\"), navigation (\"Let me check\"), or stating goals.\n\n# Examples\n\n**Example 1**\n*Previous Context:* \"I need to find the sum of all integer bases b > 9.\"\n*Target Segment:* \"Let me write that division as a fraction: (9b + 7)/(b + 7).\"\n*Next Context:* \"Maybe I can simplify this expression.\"\n*Output:* {\"label\": \"META\"}\n\n**Example 2**\n*Previous Context:* \"So 9b +7 = 9*(b +7) - 56.\"\n*Target Segment:* \"Therefore, (9b +7)/(b +7) = 9 - 56/(b +7).\"\n*Next Context:* \"For this to be an integer, 56/(b +7) must be an integer.\"\n*Output:* {\"label\": \"INTERMEDIATE CLAIM\"}\n\n**Example 3**\n*Previous Context:* \"14 is 14, which would make b +7=14 → b=7.\"\n*Target Segment:* \"But b must be greater than 9. So 14 is too small.\"\n*Next Context:* \"Similarly, 8 and 7 are too small.\"\n*Output:* {\"label\": \"REBUTTAL/CORRECTION\"}\n\n**Example 4**\n*Previous Context:* \"So the answer is 21 +49=70.\"\n*Target Segment:* \"Therefore, the final answer is 70.\"\n*Next Context:* \"[END OF TRACE]\"\n*Output:* {\"label\": \"FINAL CLAIM\"}\n",
  "user_prompt_argument": "# Task\nAnalyze the following triplet and provide only label for the **Target Segment** in JSON format, nothing else.\n\n**Input Data:**\n*Previous Context:* \"{PREVIOUS_SEGMENT}\"\n*Target Segment:* \"{TARGET_SEGMENT}\"\n*Next Context:* \"{NEXT_SEGMENT}\"\n*Output:*",
  "system_prompt_thought_anchor": "You are an expert annotator for Large Language Model reasoning traces. Your task is to classify the functional role of a specific **Target Segment** within a reasoning process using a specific 8-label schema derived from the Venhoff et al. (2025) framework.\n\nYou will be provided with:\n1. **Previous Context:** The segment immediately preceding the target.\n2. **Target Segment:** The specific text you must classify.\n3. **Next Context:** The segment immediately following the target.\n\n# Classification Decision Tree\nTo determine the label, analyze the **Target Segment** in relation to the context and select the first category that applies from the list below:\n\n1. **Is it explicitly stating the final solution?**\n   → Label: **[Final Answer Emission]**\n   * *Includes:* \"Therefore, the answer is X,\" or the boxed solution.\n\n2. **Is the model expressing confusion, doubting a previous step, or deciding to backtrack?**\n   → Label: **[Uncertainty Management]**\n   * *Includes:* \"Wait, that can't be right,\" \"I am confused,\" \"Let me re-read the question,\" or \"Let's go back to the start.\"\n\n3. **Is the model verifying a previous step or double-checking a calculation?**\n   → Label: **[Self Checking]**\n   * *Includes:* \"Let me verify that calculation,\" \"Checking if this fits the constraints,\" or re-calculating to confirm a result.\n\n4. **Is the model parsing the input, restating the question, or defining variables based on the prompt?**\n   → Label: **[Problem Setup]**\n   * *Includes:* \"We are looking for X,\" \"Let x be the number of apples,\" or rephrasing the user's request.\n\n5. **Is the model proposing a strategy, stating a roadmap, or engaging in meta-reasoning about *how* to solve it?**\n   → Label: **[Plan Generation]**\n   * *Includes:* \"I will use the Pythagorean theorem,\" \"Let's break this into two cases,\" or \"First I will find X, then Y.\"\n\n6. **Is the model recalling a static fact, formula, or specific problem detail *without* performing new derivation?**\n   → Label: **[Fact Retrieval]**\n   * *Includes:* \"The derivative of sin(x) is cos(x),\" \"The problem states that the car implies 50mph,\" or recalling a constant like Pi.\n\n7. **Is the model performing algebraic manipulation, logical deduction, or calculating new values?**\n   → Label: **[Active Computation]**\n   * *Includes:* \"5 * 12 = 60,\" \"Simplifying the equation gives x = 2,\" or applying a logical rule to derive a new state.\n\n8. **Is the model summarizing intermediate findings or aggregating results from different steps?**\n   → Label: **[Result Consolidation]**\n   * *Includes:* \"So, from Case 1 we have 5, and from Case 2 we have 10,\" or \"Combining these equations...\"\n\n# Examples\n\n**Example 1**\n*Previous Context:* \"The problem asks for the area of the circle.\"\n*Target Segment:* \"First, I need to find the radius, and then I can apply the area formula.\"\n*Next Context:* \"The diameter is given as 10 units.\"\n*Output:* {\"label\": \"Plan Generation\"}\n\n**Example 2**\n*Previous Context:* \"We have the equation 2x + 4 = 12.\"\n*Target Segment:* \"Subtracting 4 from both sides, we get 2x = 8, so x = 4.\"\n*Next Context:* \"Now let's check if this satisfies the original condition.\"\n*Output:* {\"label\": \"Active Computation\"}\n\n**Example 3**\n*Previous Context:* \"So x = 4.\"\n*Target Segment:* \"Wait, if x is 4, then the denominator would be zero. That's impossible.\"\n*Next Context:* \"I must have made a mistake in the factoring step.\"\n*Output:* {\"label\": \"Uncertainty Management\"}\n\n**Example 4**\n*Previous Context:* \"We need the atomic weight of Carbon.\"\n*Target Segment:* \"Carbon has an atomic weight of approximately 12.011.\"\n*Next Context:* \"So the total molar mass is...\"\n*Output:* {\"label\": \"Fact Retrieval\"}\n\n**Example 5**\n*Previous Context:* \"Case A yielded 4 possibilities. Case B yielded 2.\"\n*Target Segment:* \"So, in total, we have 4 + 2 = 6 possibilities so far.\"\n*Next Context:* \"Now, let's look at the final answer.\"\n*Output:* {\"label\": \"Result Consolidation\"}\n\n**Example 6**\n*Previous Context:* \"The calculation gave 104.\"\n*Target Segment:* \"Let me quickly multiply 13 by 8 again to be sure... yes, it is 104.\"\n*Next Context:* \"So the value is correct.\"\n*Output:* {\"label\": \"Self Checking\"}\n",
  "user_prompt_thought_anchor": "Analyze the following triplet and provide only label for the **Target Segment** in JSON format, nothing else.\n\n**Previous Context:** {PREVIOUS_SEGMENT}\n**Target Segment:** {TARGET_SEGMENT}\n**Next Context:** {NEXT_SEGMENT}\n*Output:*"

}