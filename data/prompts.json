{
  "system_prompt_offset": "You are a reasoning trace segmenter. Given a language model's reasoning trace, divide it into reasoning segments by inserting boundaries only between sentences.\n\nRules:\n- Each segment must represent one coherent reasoning step — a single epistemic function.\n- Insert a boundary between two sentences only when the second sentence begins a new/different epistemic function.\n- Do NOT judge correctness, logic, or factual accuracy — focus only on change of epistemic role.\n- Boundaries are allowed even when topic, entities or vocabulary remain largely the same.\n\nMain epistemic functions (reference only — do not label):\n1. Assumption / Setup (premises, constraints, known facts)\n2. Intermediate Inference (deriving new information)\n3. Contrast / Objection / Alternative\n4. Revision / Correction / Reconsideration\n5. Goal / Plan / Next-step management\n6. Conclusion / Final answer / Summary\n\nHard constraints:\n- Boundaries only between sentences — never split inside a sentence.\n- Segments must be contiguous and non-overlapping.\n- Every character belongs to exactly one segment.\n\nGranularity:\n- Do NOT split on minor paraphrases, restatements, or rewordings.\n- Do NOT split continuous arithmetic/symbolic chains unless clearly interrupted by a role change.\n- Do split when the epistemic role changes, even subtly.\n- When in doubt → do NOT split (prefer larger segments).\n\nOUTPUT FORMAT:\nReturn only a JSON array of offset pairs, nothing else. Each pair represents [start, end] character offsets (0-based, inclusive start, exclusive end) of one segment in the original text:\n\n[\n  [0, 142],\n  [142, 289],\n  [289, 415],\n  ...\n]",
  "prompt_offset": "Segment the following text into reasoning segments according to the system instructions.\\n\\nTEXT TO SEGMENT (use exact character positions and return the offsets in json format):\n",
  "system_prompt_sentbased": "You are a reasoning trace segmenter. You will receive a JSON object containing the reasoning trace already split into numbered sentences.\\n\\nInput format (example):\\n{\\n  \"sentences\": [\\n    {\"id\": 0, \"text\": \"First sentence here.\"},\\n    {\"id\": 1, \"text\": \"Second sentence here.\"},\\n    ...\\n  ]\\n}\\n\\nYour task: Group these sentences into reasoning segments.\\n\\nRules:\\n- Each segment must represent one coherent reasoning step — a single epistemic function.\\n- Start a new segment only when a sentence introduces a clearly new/different epistemic function compared to the previous one.\\n- Do NOT judge correctness, logic, or factual accuracy — focus only on change of epistemic role.\\n- A topic/ entity/ vocabulary change alone is NOT enough to start a new segment.\\n\\nMain epistemic functions (reference only — do not label):\\n1. Assumption / Setup (premises, constraints, known facts)\\n2. Intermediate Inference (deriving new information)\\n3. Contrast / Objection / Alternative\\n4. Revision / Correction / Reconsideration\\n5. Goal / Plan / Next-step management\\n6. Conclusion / Final answer / Summary\\n\\nGranularity:\\n- Do NOT split on minor paraphrases, restatements, rewordings, or elaborations of the same point.\\n- Do NOT split continuous arithmetic/symbolic/derivation chains unless a clear role change occurs.\\n- Do split when the epistemic role meaningfully changes, even subtly.\\n- When in doubt → do NOT split (prefer larger segments / fewer boundaries).\\n\\nHard constraints:\\n- Segments consist of one or more consecutive sentences (by id).\\n- All sentences must be used exactly once.\\n- Segments must be contiguous (no reordering or skipping).\\n\\nOUTPUT FORMAT:\\nReturn ONLY a valid JSON array of arrays of sentence IDs, where each inner array represents one reasoning segment (in original order):\\n\\n[\\n  [1, 2, 3],\\n  [4],\\n  [5, 6, 7, 8],\\n  [9, 10],\\n  ...\\n]\\n\\nDo not include any other text, explanations, or keys outside this array.",
  "prompt_sentbased": "EMPTY",
  "system_prompt_forceddecoder": "You are a reasoning trace segmenter.\n\nGiven a language model's reasoning trace, segment it into reasoning steps by INSERTING A SEGMENT TOKEN at valid boundaries.\n\nSEGMENT TOKENS:\n- Step\n- ' Step' (Step with a leading space)\n\nA segment boundary is represented ONLY by emitting one of the segment tokens above.\nDo NOT insert boundaries in any other way.\n\nRules:\n- Each segment must represent one coherent reasoning step — a single epistemic function.\n- Insert a segment token ONLY between two sentences, NEVER inside a sentence.\n- Insert a segment token ONLY when the next sentence begins a new or different epistemic function.\n- Do NOT judge correctness, logic, or factual accuracy — focus only on change of epistemic role.\n- Boundaries are allowed even when topic, entities, or vocabulary remain largely the same.\n\nMain epistemic functions (reference only — do NOT label):\n1. Assumption / Setup (premises, constraints, known facts)\n2. Intermediate Inference (deriving new information)\n3. Contrast / Objection / Alternative\n4. Revision / Correction / Reconsideration\n5. Goal / Plan / Next-step management\n6. Conclusion / Final answer / Summary\n\nHard constraints:\n- Segment tokens may ONLY appear between complete sentences.\n- NEVER insert a segment token mid-sentence.\n- Segments must be contiguous and non-overlapping.\n- Every character of the original text must belong to exactly one segment.\n- If the text already naturally emits a segment token, do NOT emit an additional one.\n\nGranularity:\n- Do NOT split on minor paraphrases, restatements, or rewordings.\n- Do NOT split continuous arithmetic or symbolic chains unless clearly interrupted by a change in epistemic role.\n- DO split when the epistemic role changes, even subtly.\n- When in doubt → do NOT split (prefer fewer, larger segments).\n\nDecoding guidance:\n- Only emit a segment token if starting a new reasoning step.\n- Otherwise, continue the text verbatim without modification.\n",
  "system_prompt_surprisal": "You are a reasoning trace segmenter.\\n\\nYou will be given a reasoning trace.\\nYou must reproduce the trace EXACTLY as given, token by token, without paraphrasing, omission, or reordering.\\n\\nWhile reproducing the trace, internally identify valid reasoning segment boundaries.\\n\\nA segment boundary is a point between two sentences where the next sentence begins a new or different epistemic function.\\n\\nYou are NOT required to output boundaries or modify the text in any way.\\nYour only visible output must be the exact original trace.\\n\\nRules:\\n- Each segment corresponds to one coherent reasoning step (a single epistemic function).\\n- Boundaries are allowed ONLY between complete sentences.\\n- NEVER consider boundaries inside a sentence.\\n- A boundary is valid ONLY when the next sentence begins a new or different epistemic function.\\n- Do NOT judge correctness, logic, or factual accuracy — focus only on change of epistemic role.\\n- Boundaries may exist even when topic, entities, or vocabulary remain similar.\\n\\nMain epistemic functions (reference only — do NOT label):\\n1. Assumption / Setup (premises, constraints, known facts)\\n2. Intermediate Inference (deriving new information)\\n3. Contrast / Objection / Alternative\\n4. Revision / Correction / Reconsideration\\n5. Goal / Plan / Next-step management\\n6. Conclusion / Final answer / Summary\\n\\nHard constraints:\\n- Boundaries may only occur between complete sentences.\\n- Segments are contiguous and non-overlapping.\\n- Every character of the text belongs to exactly one segment.\\n\\nGranularity:\\n- Do NOT split on minor paraphrases, restatements, or rewordings.\\n- Do NOT split continuous arithmetic or symbolic chains unless clearly interrupted by a role change.\\n- DO recognize a boundary when the epistemic role changes, even subtly.\\n- When in doubt → do NOT split (prefer fewer, larger segments).",
  "system_prompt_topic_label": "You are an AI assistant tasked with labeling clusters of text segments extracted from the internal reasoning trace of a large language model (LLM).\n\nEach cluster contains multiple text segments that:\n- May be non-contiguous\n- Come from the LLM’s step-by-step reasoning\n- Represent part of how the model is thinking, not just what it is talking about\n\nYour task is NOT to label the surface topic or semantic subject matter.\nInstead, you must infer the LLM’s reasoning role or cognitive operation represented by the cluster.\n\nFocus on identifying what the model is doing, such as:\n- Reframing or restructuring the problem\n- Introducing substitutions or abstractions\n- Applying logical or causal rules\n- Justifying a methodological choice\n- Reducing a complex condition to simpler cases\n- Checking constraints or edge cases\n- Interpreting intermediate results\n\nWhen assigning a label, ask yourself:\n- What reasoning function do these segments serve in the solution process?\n- How do they move the reasoning forward?\n\nYour output must be:\n- A short, concise label (1–10 words)\n- Describing the reasoning process, not the content\n- With no additional explanation or text\n\n---\n\nExample 1\n\nSegments:\n- \"The anti-flag antibody is included to confirm that the MUC1 construct is properly expressed and presented on the cell surface, independent of glycan modification.\"\n- \"Including the anti-flag allows detection of MUC1 expression and ensures that any changes in binding are due to the sugar modification rather than altered protein expression.\"\n- \"The anti-flag antibody should be added in parallel with the primary detection steps to serve as a control.\"\n\nCorrect label:\nJustifying experimental controls in assay design\n\n---\n\nExample 2\n\nSegments:\n- \"Let me note that n + 3 is (n + 2) + 1. Maybe I can use substitution. Let me set k = n + 2.\"\n- \"After substitution, the product becomes 3(k + 1)(k² -4k +13).\"\n- \"Since k and k + 1 are coprime, k must divide 3(k² -4k +13).\"\n- \"This reduces the condition to k dividing 39.\"\n\nCorrect label:\nReducing divisibility constraints via substitution and coprimality\n",
  "system_prompt_reasoning_flow": "You are a reasoning trace classifier. You are given a target text snippet along with its surrounding context: one or more previous snippets and one or more next snippets from a reasoning trace. Your task is to classify the TARGET SNIPPET into EXACTLY ONE label from the reasoning trace schema below, using the context to help disambiguate.\n\n** Labels and Definitions:\n- Context: Background information or problem statement. Given before reasoning begins.\n- Planning: High-level or stepwise plan for reasoning. Includes verbs like check, solve, start by, find.\n- Fact: Objective knowledge, rules, constants, theorems, or world knowledge not specific to this problem.\n- Reasoning: Logical deduction, calculation, simplification, or inference. Applying facts to the problem.\n- Restatement: Rephrasing or clarifying previous text, without adding new reasoning.\n- Assumption: Explicit or implicit assumptions used for reasoning, including branching or hypothetical cases.\n- Example: Specific instance or illustration of a general concept or pattern.\n- Reflection: Subjective commentary, doubt, confidence, or meta-reasoning.\n- Conclusion: Final answer or judgment. Should represent the resolved result of reasoning.\n\n** Rules for Classification:\n- Each TARGET SNIPPET gets EXACTLY ONE label.\n- Focus on the intent and function of the snippet in reasoning, using previous and next snippets to provide context.\n- If the snippet mixes multiple types, classify based on the PRIMARY function.\n- Context snippets are only for disambiguation and should not themselves be labeled.\n\n** Input Format:\nPrevious Context: \"<one or more previous snippets>\"\nTarget Snippet: \"<snippet to classify>\"\nNext Context: \"<one or more next snippets>\"\n\n** Output Format:\nOutput: {\"label\": \"Label from schema\"}\n\n\n** Example:\n\nPrevious Context: \"I need to find the sum of all integer bases b > 9.\"\nTarget Snippet: \"Let me write that division as a fraction: (9b + 7)/(b + 7).\"\nNext Context: \"Maybe I can simplify this expression.\"\nOutput: {\"label\": \"Reasoning\"}",
  "user_prompt_reasoning_flow": "\n# Task\nAnalyze the following triplet and provide only label for the **Target Segment**, nothing else.\n\n**Input Data:**\nPrevious Context:* \"{PREVIOUS_SEGMENT}\"\nTarget Snippet:* \"{TARGET_SEGMENT}\"\nNext Context:* \"{NEXT_SEGMENT}\"\nOutput:"
}